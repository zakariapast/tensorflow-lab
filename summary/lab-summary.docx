# Manager-facing summary (for PDF export)
ğŸ§ª Lab Summary â€“ Part 1: Baseline Model Without Privacy
Objective: Train a simple image classification model using TensorFlow to recognize handwritten digits from the MNIST dataset. This serves as the baseline before adding privacy protections.

ğŸŸ© Environment Preparation
Step	Detail
Platform	Google Colab (recommended for GPU + easy setup)
Tools Installed	tensorflow, tensorflow-privacy
Fix Applied	Upgraded packaging to fix dependency error

ğŸ“¦ Dataset Used
Dataset	Description
MNIST	70,000 grayscale images of handwritten digits (28Ã—28 pixels)
Training Set	60,000 images
Test Set	10,000 images
Labels	Integers 0 to 9

ğŸ§± Model Architecture (Baseline)
Layer	Description
Flatten	Converts 28Ã—28 image to 784 vector
Dense(128, relu)	Hidden layer with 128 units
Dense(10)	Output layer for 10 digit classes (0â€“9)

âš™ï¸ Training Configuration
Parameter	Value
Optimizer	adam
Loss	SparseCategoricalCrossentropy(from_logits=True)
Epochs	5
Validation Split	10% of training data

ğŸ“ˆ Training Results
Epoch	Accuracy	Val Accuracy	Loss	Val Loss
1	86.5%	96.4%	0.47	0.12
5	98.6%	97.8%	0.04	0.07

âœ… Model performs very well, but privacy risk exists: It could overfit or leak data through future attacks.
==============================================================================================================================================
ğŸ§ª Lab Summary â€“ Part 2: Model with Differential Privacy (DP)
Objective: Train a model using TensorFlow Privacy to protect individual data points and mitigate the risk of data leakage (e.g. membership inference attacks).

ğŸŸ© Differential Privacy Setup
Component	Value
Optimizer	DPKerasAdamOptimizer
L2 Norm Clip	1.0
Noise Multiplier	1.1 (Gaussian noise added)
Microbatches	250
Batch Size	250
Loss Function	SparseCategoricalCrossentropy with reduction=None
Epochs	5
Dataset	MNIST (handwritten digits)

âš™ï¸ Model Architecture
Layer	Type	Notes
Flatten	Input	28Ã—28 to 784
Dense(128, relu)	Hidden	Fully connected
Dense(10)	Output	10 classes

ğŸ“ˆ Training Results (DP Model)
Epoch	Train Accuracy	Validation Accuracy	Train Loss	Validation Loss
1	83.7%	89.2%	0.5206	0.3606
2	86.7%	90.3%	0.4422	0.3254
3	87.9%	91.1%	0.4201	0.3110
4	88.6%	91.4%	0.4100	0.3068
5	89.1%	91.5%	0.4069	0.3056

ğŸ” Privacy Observations
Accuracy is slightly lower than the baseline model, but data exposure risk is reduced.

The model generalizes well despite added noise.

This setup aligns with privacy-preserving AI goals in production systems.

ğŸ†š Comparison to Baseline (No DP)
Metric	Baseline Model	DP Model
Final Train Acc	98.6%	89.1%
Final Val Acc	97.8%	91.5%
Privacy Level	âŒ None	âœ… Enforced
Use Case	High accuracy	Privacy critical scenarios
