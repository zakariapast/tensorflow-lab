# Manager-facing summary (for PDF export)
🧪 Lab Summary – Part 1: Baseline Model Without Privacy
Objective: Train a simple image classification model using TensorFlow to recognize handwritten digits from the MNIST dataset. This serves as the baseline before adding privacy protections.

🟩 Environment Preparation
Step	Detail
Platform	Google Colab (recommended for GPU + easy setup)
Tools Installed	tensorflow, tensorflow-privacy
Fix Applied	Upgraded packaging to fix dependency error

📦 Dataset Used
Dataset	Description
MNIST	70,000 grayscale images of handwritten digits (28×28 pixels)
Training Set	60,000 images
Test Set	10,000 images
Labels	Integers 0 to 9

🧱 Model Architecture (Baseline)
Layer	Description
Flatten	Converts 28×28 image to 784 vector
Dense(128, relu)	Hidden layer with 128 units
Dense(10)	Output layer for 10 digit classes (0–9)

⚙️ Training Configuration
Parameter	Value
Optimizer	adam
Loss	SparseCategoricalCrossentropy(from_logits=True)
Epochs	5
Validation Split	10% of training data

📈 Training Results
Epoch	Accuracy	Val Accuracy	Loss	Val Loss
1	86.5%	96.4%	0.47	0.12
5	98.6%	97.8%	0.04	0.07

✅ Model performs very well, but privacy risk exists: It could overfit or leak data through future attacks.
==============================================================================================================================================
🧪 Lab Summary – Part 2: Model with Differential Privacy (DP)
Objective: Train a model using TensorFlow Privacy to protect individual data points and mitigate the risk of data leakage (e.g. membership inference attacks).

🟩 Differential Privacy Setup
Component	Value
Optimizer	DPKerasAdamOptimizer
L2 Norm Clip	1.0
Noise Multiplier	1.1 (Gaussian noise added)
Microbatches	250
Batch Size	250
Loss Function	SparseCategoricalCrossentropy with reduction=None
Epochs	5
Dataset	MNIST (handwritten digits)

⚙️ Model Architecture
Layer	Type	Notes
Flatten	Input	28×28 to 784
Dense(128, relu)	Hidden	Fully connected
Dense(10)	Output	10 classes

📈 Training Results (DP Model)
Epoch	Train Accuracy	Validation Accuracy	Train Loss	Validation Loss
1	83.7%	89.2%	0.5206	0.3606
2	86.7%	90.3%	0.4422	0.3254
3	87.9%	91.1%	0.4201	0.3110
4	88.6%	91.4%	0.4100	0.3068
5	89.1%	91.5%	0.4069	0.3056

🔐 Privacy Observations
Accuracy is slightly lower than the baseline model, but data exposure risk is reduced.

The model generalizes well despite added noise.

This setup aligns with privacy-preserving AI goals in production systems.

🆚 Comparison to Baseline (No DP)
Metric	Baseline Model	DP Model
Final Train Acc	98.6%	89.1%
Final Val Acc	97.8%	91.5%
Privacy Level	❌ None	✅ Enforced
Use Case	High accuracy	Privacy critical scenarios
